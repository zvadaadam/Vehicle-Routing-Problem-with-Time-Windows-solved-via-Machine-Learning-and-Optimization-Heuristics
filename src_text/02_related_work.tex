\chapter{Related work}\label{related_work}
    In this chapter, we briefly present relevant work addressing similar problems in \gls{mot} and soft-biometrics field. Given the vastness of the topic, we only limit the review to significant work.

\section{\Glsentrylong{mot}}
     Most state-of-the-art algorithms addressing \gls{mot} follow the tracking-by-detection approach, which heavily relies on the performance of the underlying object detector. However, the trend is now shifting to the end-to-end learning solutions and constructing stronger similarity scores based on appearance, motion, and interaction cues. Although recent \gls{nn} based detectors have outperformed all other methods for object detection \cite{russakovsky2015imagenet, ren2015faster, redmon2016you}, \gls{mot} remains a challenging and popular topic.
   
    \Gls{sort} \cite{bewley2016simple} is the first pragmatic approach where the main focus is to associate objects efficiently for online and real-time applications. They showed that the quality of detections plays a crucial role in tracking performance and according to their experiments, they can improve tracking by almost 20 \%, depending on the detector. Despite using an only simple combination of standard techniques as the Kalman Filter for motion prediction and Hungarian algorithm for the association of the tracks, they were able to achieve comparable performance to other state-of-the-art online trackers. 
    
    By adding a deep association metric to \gls{sort} \cite{wojke2017simple}, it was successfully integrated with the appearance model that improves the tracking performance. The appearance model is based on \gls{cnn} trained on large scale person \gls{reid} dataset. Due to this extension, the algorithm can track objects through longer periods of occlusion, effectively reducing the number of identity switches. The framework of this paper is used for our tracking task. Thus it is more explained in the next chapter. 

    In 2016, revolutionary end-to-end learning approach based on \gls{rnn} \cite{mikolov2010recurrent} has been introduced in a novel \cite{milan2017online}. Their proposed \gls{lstm} \cite{hochreiter1997long} architecture is capable of performing all multi-target tracking tasks including prediction, data association, state update as well as initiation and termination of targets within a unified network structure. One of the main advantages of this approach is that it is completely model-free, i.e., it does not require any prior knowledge about target dynamics, clutter distributions, etc. However, the object detections should be given as input.
    
    It was not the only case of successful use of \gls{rnn}. In the paper \cite{sadeghian2017tracking} published year later, a new approach combining multiple cues such as appearance, movement, and interaction is proposed. These cues are fed into \gls{lstm} \cite{hochreiter1997long} architecture, which learns and remembers the dependencies in a sequence of observation, in contrast to pairwise similarity where only the observations from the current and previous frames are used. Their proposed framework follows end-to-end fashion, and their architecture does not require object detections as input.
    
    Competitive tracking results can be achieved even without sophisticated tracking methods. Tractor \cite{DBLP:journals/corr/abs-1903-05625} accomplishes tracking without following the common tracking-by-detection approach and authors performed no training or optimization on tracking data. Instead, they exploited the bounding box regression of an object detector to perform temporal realignment and to predict the position of an object in the next frame. They also provide a simple extension to this approach, in the form of Siamese \gls{nn} for \gls{reid} and motion analysis model, which achieve state-of-the-art performance on tracking benchmarks. 
    
    Results of recent tracking evaluations show that bounding box tracking performance is saturating \cite{mot16}. Further improvements will only be possible when moving to the pixel level., which is a reason why the authors of recent 2019 work \cite{DBLP:journals/corr/abs-1902-03604} are expanding from \gls{mot} to \gls{mots}. They propose new TrackR-CNN baseline method which jointly addresses detection, tracking, and segmentation with a single convolutional network that extends Mask R-CNN architecture with 3D convolutions to incorporate temporal information, and by an association head which is used to link object identities over time. They also provide evaluation metrics and new dataset with masks for over one thousand distinct objects in ten thousand frames. The main advantage of \gls{mots} is that segmentation based tracking results, are by definition non-overlapping and can thus be compared to ground truth straightforwardly.
    
\section{Soft-biometrics}
    There has not been much written about the general use of biometrics in retail yet. However, some exceptions exist. For example, in \cite{fookes2010semi} authors propose semi-supervised intelligent multi-camera surveillance framework that can perform multiple tasks, including camera management, camera calibration, and multi-view object tracking with \gls{reid} based on appearance soft-biometric traits. The survey \cite{quintana2016improving} from 2016 provides a complete overview of innovative camera approaches that can be applied in the retail environment. The study \cite{de2018comparative} aims at recognizing the age, gender, presence of eyeglasses and beard of passers-by in a retail store. Their solution lies in custom \gls{cnn} architecture that extracts these traits.
    
    Although end-to-end solution targeting solely retail environment have not been proposed yet, there are plenty of works that deal only with certain soft-biometric features.
   
    \subsection{Body traits}
        Frequent body traits \cite{de2018comparative} extracted from an \gls{rgb} camera are height, gait, and color of clothes. The best feature for distinctiveness between individuals proved to be gait, which is the reason why it is often used in forensic analysis. However, there are not many uses for gait in the retail environment. Thus we only focus on others.
        
        \subsubsection{Height estimation}
            There has been a long history in determining an individual's height. One of the essential works in this field is \cite{criminisi2002single}, where authors proved that height estimation is possible without any information about camera parameters, only several scene correspondences with known real-world measurements are sufficient. In their work, they also describe how the affine 3D geometry of a scene can be reconstructed from a single image.
            
            In \cite{viswanath2009simplified} authors describe a simple uncalibrated model of error distribution in height as a function of the location of the object in the image and the estimated camera height. Their approach builds on previous work \cite{criminisi2002single} and improves the accuracy in estimating the height while reducing the burden of reliably computing the ground plane. 
        
            More recent work \cite{momeni2012height} uses a single calibrated camera, more explicitly assuming the knowledge about its pose concerning the world and vanishing point in the reference direction. According to their proposed theorem, by knowing the proportion of camera height concerning the object height, at the object’s position in the image plane, it is possible to estimate the height of the object in the real world. Their presented method gives accurate results in unstructured environments, regardless of the relative distance from the camera.
            
            Authors of \cite{li2015simplified} proposed a framework utilizing the calibrated camera for estimating height in video surveillance. Their primary assumption is that it is possible to obtain a camera's focal length, tilting angle, and height by using non-linear regression model from the observer's head and foot points of people in the scene, instead of estimating the vanishing point and vanishing line. Once these calibration parameters of a camera are obtained, the physical height of a person can be estimated from a pair of head and foot points observed from the image and their proposed formula.

        \subsubsection{Color clothes estimation}
            One of the essential works \cite{yamaguchi2012parsing} in this field comes from 2012, where authors focus on fashion photographs and propose an effective method to produce intricate and accurate parse of a person’s outfit. They also introduced large labeled dataset with available labeling tools. Finally, they designed a prototype application for visual garment search.
            
            DeepFashion \cite{liu2016deepfashion} is another large-scale clothes dataset with extensive annotations introduced in 2016. Authors also introduced a new baseline method, namely FashionNet, which learns clothing features by jointly predicting clothing attributes and landmarks. The estimated landmarks are then employed to pool or gate the learned features. 
            
            The current state-of-the-art is the baseline model built upon Mask R-CNN \cite{he2017mask}, termed Match R-CNN \cite{ge2019deepfashion2}. The authors of this work also proposed new challenging large-scale dataset DeepFashion2. Their presented model offers end-to-end training framework that jointly learns clothes detection, landmark estimation, instance segmentation, and consumer-to-shop retrieval. 

    \subsection{Facial traits}
        If we focus only on the head of individuals, then many algorithms targeting facial biometric \cite{wang2018deep} are regularly introduced. Most of the work from this field comes inevitably from face recognition task, which is natural since this field has a history almost as long as fingerprint recognition. Commonly extracted facial soft-biometrics are gender, ethnicity, age, emotion, pose, glasses, beard, and mustache with a frequent goal to explore their discrimination capabilities among other individuals during in-the-wild scenarios. We will limit this review to only the most important ones that can be used for retail use, namely age, gender, emotion, and pose \cite{balaban2015deep}. Some of these traits are commonly estimated together by using one model.
        
        \subsubsection{Multi-task approaches}
            In paper \cite{yin2018multi}, authors propose multi-task \gls{cnn} for face recognition where identity classification is the main task and pose, illumination, and expression estimations are the side tasks. They also provide analysis of multi-task learning with extensive experiments that demonstrate the effectiveness of the proposed approach.
            
            HyperFace \cite{ranjan2019hyperface} is an algorithm that can simultaneously do face detection, landmarks localization, pose estimation and gender recognition. It uses \gls{cnn} model architecture that fuses intermediate layers of a \gls{cnn} using a separate \gls{cnn} followed by a multi-task learning algorithm that operates on the fused features. It exploits the synergy among the tasks which boosts up their performances. They also proposed two variants with a different focus -- HyperFace-ResNet that achieves high accuracy and Fast-HyperFace that significantly improves the speed of the algorithm. Their experiments show that the proposed models can capture both global and local information in faces and perform significantly better than many competitive algorithms for each of these four tasks.
            
            The authors of the same composition later released improved version \cite{ranjan2017all} that can additionally solve for tasks of smile detection, age estimation, and face recognition. They also extended their approach by training the model on multiple datasets whereas HyperFace was trained only on one. 

        \subsubsection{Age and gender estimation}\label{age_and_gender_estimation_related}
            In most retail cases, we are interested in estimating age at the same time as gender \cite{ranjan2017all, wang2015deeply}, since these traits play a crucial role in targeted advertising. In the case of age, it is very challenging to obtain it by the camera because the apparent age sometimes significantly differ from the real one. Fortunately, particular numbers are not that important, but instead categories such as child, youth, adult, middle-age and elderly. On the other hand with gender, the situation is slightly simpler because there are several other attributes that algorithms can use. We further present only recent proposals from this field that mostly relies on \gls{dl} models. 
            
            The first ever work applying \gls{dl} methods was presented by the authors in \cite{wang2015deeply}. They propose a \gls{cnn}-based framework for age estimation, and instead of using only the feature map obtained at the top layer, they utilize feature maps obtained in different layers for the final estimation. Additionally, they incorporate a manifold learning algorithm in the proposed scheme, and that significantly improves the performance.

            In the same year, work \cite{rothe2015dex} introduced \gls{dex} method that tackles the estimation of apparent age in face images. They proposed \gls{cnn} with VGG-16 architecture pre-trained on ImageNet. They also introduced large-scale face images dataset with available age to pre-train their \gls{cnn}. 

            Recently in 2019, authors of \cite{yang2018ssr} proposed \gls{ssr}, a light-weight \gls{cnn} model with real-time performance that is targeting age and gender estimation. Their work is inspired by DEX, and they address age estimation by performing multi-class classification and then turning classification results into regression by calculating the expected values. Their greatest benefit is the compactness of the model presented. \Glsentryshort{ssr} takes only 0.32 MB of memory, and despite its size, it is approaching the performance of more than 1500× larger state-of-the-art methods.
            
        \subsubsection{Facial expression recognition}
            Facial expression \cite{goodfellow2013challenges} is one of the main clues that can be utilized in retail stores to measure the satisfaction of the consumers. \cite{arriaga2017real} is a very popular paper that proposes a general \gls{cnn} framework with real-time performance. Their model is capable of accomplishing the tasks of face detection, gender classification, and emotion classification simultaneously in one blended step using the proposed architecture. They validate their results on recent datasets, but also by building their robot which succeeded in the competition. Their architecture and pre-trained models are released under an open-source license.

            The framework known as EmoPy \cite{emopy} is a toolkit with multiple implemented \gls{cnn} architectures for emotion recognition. For example, they use time-delayed 3-D \gls{cnn}  that utilizes temporal information as part of its training samples. In other words, instead of using an only single image for prediction, it uses past images from a series for additional context. The idea is to capture the progression of a facial expression leading up to a peak emotion. They also propose hybrid \gls{lstm} \cite{hochreiter1997long} architecture that combines approaches from \gls{cnn} and \gls{rnn} to include temporal context from whole still images, not only from face patches as the former presented. They also introduce a simpler model trained on FER2013 dataset \cite{goodfellow2013challenges} which can make predictions based on a single image. Moreover, in their framework, it is possible to specify only a smaller subset of all seven emotions available, which is undoubtedly more practical in real-world scenarios.
            
            Paper \cite{zeng2018facial} from 2018 has presented a novel approach for facial expression recognition using \gls{dsae} \cite{sun2016sparse}, which can automatically distinguish the expressions with high accuracy. Both the facial geometric and appearance features have been introduced to compose a high-dimensional feature with accurate and comprehensive information of emotions. In the end, the experiment results have demonstrated that the proposed approach outperforms the other three state-of-the-art methods by a large margin.
             
        \subsubsection{Head pose estimation}
            Head pose estimation \cite{wang2018deep} is closely related to other facial analysis problems, and it might be useful in a retail store when there is a requirement for modeling customer attention on specific products or areas. Traditional algorithms work by estimating facial landmarks (key points) from the target face and then solving the 2D to 3D correspondence problem with a mean human head model as a reference. Since it is a very fragile method that relies on landmark detection performance, current state-of-the-art methods focus on detecting the pose without detecting the key points. 
            
            In 2018, an accurate and easy to use head pose estimation \gls{cnn} known as Hopenet \cite{Ruiz_2018_CVPR_Workshops} was introduced. In their work, authors can detect intrinsic Euler angles (yaw, pitch, and roll) directly from image intensities through joint binned pose classification and regression. They showed their network generalization capacity by testing the performance on various external datasets without fine-tuning. 
        
            A novel method is known as FSA-Net \cite{fsanet} also targets head pose estimation. Authors of this work proposed a light-weight non-landmark \gls{cnn} model that even outperforms methods utilizing multi-modality information from depth and \gls{rgb} cameras.