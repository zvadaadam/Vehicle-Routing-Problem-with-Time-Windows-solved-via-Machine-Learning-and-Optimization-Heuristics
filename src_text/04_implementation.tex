\chapter{Implementation}
    This chapter contains information related to the implementation of the proposed framework. The whole implementation is done in Python language with the dependence on several other frameworks and libraries, including OpenCV, Tensorflow, and Darknet. The main application functionality spans eight Python modules.
    
\section{Module tracking\textunderscore app}
    This module is the main entry point of the application. It contains only one essential function that is responsible for running the proposed framework. In this function, we first load the input image stream, calibration parameters and other components such as object detectors, feature extractors, tracker, and image viewer. Then there is a loop that runs the algorithms as long as input frames are available. The application can be run either from an IDE or from the command line with various input parameters.

\section{Module detection}
    The detection module contains multiple wrappers for various object and face detectors proposed in \ref{detection_and_tracking_components}. It is responsible for loading these models based on input parameters, detecting objects in the input frame, and filtering detections by input criteria. 

\section{Module feature\textunderscore extraction}
    In this module, we propose to interface and pre-processing to various appearance feature extractors including age, gender, and emotion models, but also height estimator. The module also contains a function that assigns face regions to people bounding boxes.

\section{Module kalman\textunderscore filter}
    This module is vital for the proposed motion analysis method because it contains the configuration of the utilized filter. Our approach uses Kalman Filter implementation from famous FilterPy \cite{labbe2015kalman} library. The module is also responsible for converting filter's internal state to visualizable bounding box and for converting measurements to filter's input.

\section{Module matching}
    The matching module contains an efficient implementation of a proposed distance metric, namely the cosine metric for appearance (section \ref{appearance_metric}) and enhanced Euclidean distance for the state (section \ref{state_metric}). Metrics are calculated by NumPy, which is a high-performance linear algebra library written in C language. To make the computations as efficient as possible, we utilize the NumPy broadcasting technique.

\section{Module tracking}
    In the tracking module, we propose PeopleTracker class that is responsible for the actual matching of detections and tracks. It is mostly inspired by code from \cite{wojke2017simple}, but some modifications in the matching algorithm were made. Successfully matched tracks are updated from here, and unmatched detections are transformed to tentative tracks.
    
\section{Module track}
    An instance of Person class from the track module represents a single person that was detected in the scene. Each person instance has set of attributes including id, color for visualization, status, creation frame number, time since the last update, age in frame units, last body bounding box, last face bounding box, Kalman filter instance, and dictionary with gathered features.
    
\section{Module output\textunderscore statistics}
    This module is responsible for transforming all possible data to brief output statistics. It includes a class TrackingEvaluator which evaluates the tracking performance of the algorithm based on provided annotations. Class OutputStatistics is responsible for converting gathered data about people to usable outputs.

\section{Module visualization}
    Visualization module contains all drawing related functions including plotting output graphs using Matplotlib and Seaborn libraries. It implements an ImageViewer class that is responsible for showing the preview of processed images. The ImageViewer class also contains functionality that allows easier debugging by allowing users to pause the algorithm or process the stream by one frame at a time.